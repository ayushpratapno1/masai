{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83e\udde0 Natural Language Processing Programs\n", "\n", "This notebook contains demo programs for:\n", "- Sentiment Analysis using HuggingFace Transformers\n", "- Sentiment Analysis using Naive Bayes\n", "- AI Chatbot using DialoGPT"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install transformers"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u2705 Sentiment Analysis using HuggingFace\n", "from transformers import pipeline\n", "\n", "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n", "\n", "sentences = [\n", "    \"I love this product, it\u2019s amazing!\",\n", "    \"This is the worst service I\u2019ve ever had.\",\n", "    \"The movie was okay, not great but not terrible.\"\n", "]\n", "\n", "for sentence in sentences:\n", "    result = sentiment_pipeline(sentence)[0]\n", "    print(f\"Sentence: {sentence}\")\n", "    print(f\"Label: {result['label']}, Confidence: {round(result['score'], 3)}\\n\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u2705 Sentiment Analysis using Naive Bayes (Simulated IMDb)\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.feature_extraction.text import CountVectorizer\n", "from sklearn.naive_bayes import MultinomialNB\n", "from sklearn.pipeline import make_pipeline\n", "\n", "texts = [\n", "    \"I absolutely loved the film!\",\n", "    \"It was a terrible experience.\",\n", "    \"An okay performance.\",\n", "    \"Not my type of movie.\",\n", "    \"A must-watch!\"\n", "]\n", "labels = [1, 0, 1, 0, 1]\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.4)\n", "model = make_pipeline(CountVectorizer(), MultinomialNB())\n", "model.fit(X_train, y_train)\n", "\n", "predictions = model.predict(X_test)\n", "for sentence, pred in zip(X_test, predictions):\n", "    label = \"Positive\" if pred == 1 else \"Negative\"\n", "    print(f\"Text: {sentence}\\nPredicted Sentiment: {label}\\n\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u2705 Simple AI Chatbot using DialoGPT\n", "from transformers import AutoModelForCausalLM, AutoTokenizer\n", "import torch\n", "\n", "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-small\")\n", "model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-small\")\n", "\n", "print(\"Start chatting with the bot (type 'quit' to stop)\")\n", "chat_history_ids = None\n", "step = 0\n", "\n", "while True:\n", "    user_input = input(\"User: \")\n", "    if user_input.lower() == \"quit\":\n", "        break\n", "\n", "    new_input_ids = tokenizer.encode(user_input + tokenizer.eos_token, return_tensors='pt')\n", "    bot_input_ids = torch.cat([chat_history_ids, new_input_ids], dim=-1) if step > 0 else new_input_ids\n", "    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n", "    bot_output = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n", "    print(f\"Bot: {bot_output}\")\n", "    step += 1"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9"}}, "nbformat": 4, "nbformat_minor": 5}